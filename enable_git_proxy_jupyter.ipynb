{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09428fe1-c76a-4d03-8deb-acbd94050594",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Enable Git Proxy for private Git server connectivity in Repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d139a95c-8953-4a5a-8373-38e0d52b084a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Overview\n",
    "This private preview feature is available on AWS, Azure and GCP.\n",
    "\n",
    "**Note**: an *admin* must run this notebook to enable the feature.\n",
    "\n",
    "\"Run all\" this notebook to set up a cluster that proxies requests to your private Git server. Running this notebook does the following things:\n",
    "\n",
    "0. Creates a [single node cluster](https://docs.databricks.com/clusters/single-node.html) to run Git Proxy on it. **Important**: all users in the workspace will be granted \"attach to\" permissions to the cluster.\n",
    "0. Enables a feature flag that controls whether Git requests in Repos are proxied via the cluster.\n",
    "\n",
    "You may need to wait several minutes after running this notebook for the cluster to reach a \"RUNNING\" state. It can also take up to 5 minutes for the feature flag configuration to take effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e1623df-034f-4853-b544-cf70a491702d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create the proxy cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48beb9ca-d6a5-4ebd-9370-17035d3af9de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Setup admin token and HTTP requests\n",
    "Get the admin token from current context, prepare HTTP requests for Databricks APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94ae215e-ea5a-4e45-b31a-e6bd0effbc85",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "admin_token = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    ")\n",
    "databricks_instance = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    ")\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {admin_token}\"}\n",
    "\n",
    "# Clusters\n",
    "CLUSTERS_LIST_ENDPOINT = \"/api/2.0/clusters/list\"\n",
    "CLUSTERS_CREATE_ENDPOINT = \"/api/2.0/clusters/create\"\n",
    "CLUSTERS_LIST_NODE_TYPES_ENDPOINT = \"/api/2.0/clusters/list-node-types\"\n",
    "CLUSTERS_GET_ENDPOINT = \"/api/2.0/clusters/get\"\n",
    "\n",
    "# Permissions\n",
    "UPDATE_PERMISSIONS_ENDPOINT = \"/api/2.0/permissions/clusters\"\n",
    "\n",
    "# Workspace Conf\n",
    "WORKSPACE_CONF_ENDPOINT = \"/api/2.0/workspace-conf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a33316f-5212-4561-b3f0-d971d3fdc619",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create the cluster\n",
    "Call Databricks Cluster API to create the Git Proxy cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af9eb9d-f298-465f-83f3-7464fbbbd184",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cluster_name = \"Repos Git Proxy\"\n",
    "create_cluster_data = {\n",
    "    \"cluster_name\": cluster_name,\n",
    "    \"spark_version\": \"12.2.x-scala2.12\",\n",
    "    \"num_workers\": 0,\n",
    "    \"autotermination_minutes\": 0,\n",
    "    \"spark_conf\": {\n",
    "        \"spark.databricks.cluster.profile\": \"singleNode\",\n",
    "        \"spark.master\": \"local[*]\",\n",
    "    },\n",
    "    \"custom_tags\": {\"ResourceClass\": \"SingleNode\"},\n",
    "}\n",
    "# get list of node types to determine whether this workspace is on AWS or Azure\n",
    "clusters_node_types = requests.get(\n",
    "    databricks_instance + CLUSTERS_LIST_NODE_TYPES_ENDPOINT, headers=headers\n",
    ").json()[\"node_types\"]\n",
    "node_type_ids = [type[\"node_type_id\"] for type in clusters_node_types]\n",
    "aws_node_type_id = \"m5.large\"\n",
    "azure_node_type_id = \"Standard_DS3_v2\"\n",
    "gcp_node_type_id = \"e2-standard-4\"\n",
    "if aws_node_type_id in node_type_ids:\n",
    "    create_cluster_data = {\n",
    "        **create_cluster_data,\n",
    "        \"node_type_id\": aws_node_type_id,\n",
    "        \"aws_attributes\": {\"ebs_volume_count\": \"1\", \"ebs_volume_size\": \"32\", \"first_on_demand\": \"1\"},\n",
    "    }\n",
    "elif azure_node_type_id in node_type_ids:\n",
    "    create_cluster_data = {**create_cluster_data, \"node_type_id\": azure_node_type_id}\n",
    "elif gcp_node_type_id in node_type_ids:\n",
    "    create_cluster_data = {**create_cluster_data, \"node_type_id\": gcp_node_type_id}\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Node types {aws_node_type_id} or {azure_node_type_id} do not exist. Make sure you are on AWS or Azure, or contact support.\"\n",
    "    )\n",
    "\n",
    "# Note: this only returns up to 100 terminated all-purpose clusters in the past 30 days\n",
    "clusters_list_response = requests.get(\n",
    "    databricks_instance + CLUSTERS_LIST_ENDPOINT, headers=headers\n",
    ").json()\n",
    "clusters_list = clusters_list_response[\"clusters\"]\n",
    "clusters_names = [\n",
    "    cluster[\"cluster_name\"] for cluster in clusters_list_response[\"clusters\"]\n",
    "]\n",
    "print(f\"List of existing clusters: {clusters_names}\")\n",
    "\n",
    "if cluster_name in clusters_names:\n",
    "    raise ValueError(\n",
    "        f\"Cluster called {cluster_name} already exists. Please delete this cluster and re-run this notebook\"\n",
    "    )\n",
    "else:\n",
    "    # Create a new cluster named cluster_name that will proxy requests to the private Git server\n",
    "    print(f\"Create cluster POST request data: {create_cluster_data}\")\n",
    "    clusters_create_response = requests.post(\n",
    "        databricks_instance + CLUSTERS_CREATE_ENDPOINT,\n",
    "        headers=headers,\n",
    "        json=create_cluster_data,\n",
    "    ).json()\n",
    "    print(f\"Create cluster response: {clusters_create_response}\")\n",
    "    cluster_id = clusters_create_response[\"cluster_id\"]\n",
    "    print(f\"Created new cluster with id {cluster_id}\")\n",
    "    update_permissions_data = {\n",
    "        \"access_control_list\": [\n",
    "            {\"group_name\": \"users\", \"permission_level\": \"CAN_ATTACH_TO\"}\n",
    "        ]\n",
    "    }\n",
    "    update_permissions_response = requests.patch(\n",
    "        databricks_instance + UPDATE_PERMISSIONS_ENDPOINT + f\"/{cluster_id}\",\n",
    "        headers=headers,\n",
    "        json=update_permissions_data,\n",
    "    ).json()\n",
    "    print(f\"Update permissions response: {update_permissions_response}\")\n",
    "    print(f\"Gave all users ATTACH TO permissions to cluster {cluster_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e588938a-e523-46cf-99de-a9932c6d7174",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Wait for the cluster to be ready\n",
    "\n",
    "Before we can send traffic to it, we should wait for the cluster to be up and ready to serve traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "631cebda-ffc1-4f89-8e20-82466b780bc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "sleep_time_s = 10\n",
    "\n",
    "state = None\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    clusters_get_response = requests.get(\n",
    "        url=databricks_instance + CLUSTERS_GET_ENDPOINT,\n",
    "        headers=headers,\n",
    "        params={\"cluster_id\": cluster_id }\n",
    "    ).json()\n",
    "    state = clusters_get_response.get(\"state\", None)\n",
    "    if state == 'RUNNING':\n",
    "        print(\"Cluster is ready!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Cluster is in state %s, waiting for %s seconds and trying again\" % (state, sleep_time_s))\n",
    "        time.sleep(sleep_time_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec1268f-5134-4bf5-9fc0-23140492558b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Flip the feature flag!\n",
    "This flips the feature flag to route Git requests to the cluster. The change should take into effect within an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0829abfd-638c-4db1-9da4-d2c9e219f53f",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "patch_enable_git_proxy_data = {\"enableGitProxy\": \"true\"}\n",
    "patch_git_proxy_cluster_name_data = {\"gitProxyClusterId\": cluster_id}\n",
    "requests.patch(\n",
    "    databricks_instance + WORKSPACE_CONF_ENDPOINT,\n",
    "    headers=headers,\n",
    "    json=patch_enable_git_proxy_data,\n",
    ")\n",
    "requests.patch(\n",
    "    databricks_instance + WORKSPACE_CONF_ENDPOINT,\n",
    "    headers=headers,\n",
    "    json=patch_git_proxy_cluster_name_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "814082f8-5526-4835-b864-0a426c1b6926",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Check that flag has been set\n",
    "If the command below returns with `{\"enableGitProxy\":\"true\"}`, you should be all set. Also, if you configured a custom cluster name using the widget, check that the cluster name in the response matches the name you specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68066546-21ff-4523-a5dc-9760b225474a",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "get_flag_response = requests.get(\n",
    "    databricks_instance + WORKSPACE_CONF_ENDPOINT + \"?keys=enableGitProxy\",\n",
    "    headers=headers,\n",
    ").json()\n",
    "get_cluster_id_response = requests.get(\n",
    "    databricks_instance + WORKSPACE_CONF_ENDPOINT + \"?keys=gitProxyClusterId\",\n",
    "    headers=headers,\n",
    ").json()\n",
    "print(f\"Get enableGitProxy response: {get_flag_response}\")\n",
    "print(f\"Get gitProxyClusterId response: {get_cluster_id_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "120f1fcc-abc2-49d8-acd0-6eaaca0f9e9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Wait for the cluster, and more configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "735e9217-6cd7-41b2-9d7a-0caf3a19d795",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Wait for the cluster to be ready\n",
    "Please wait for the cluster to be ready, you can check the cluster status at [Compute](#setting/clusters), the cluster name is \"Repos Git Proxy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e944a34-e628-46be-b110-ba474ee48921",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### More configuration (only needed if the Git Proxy not working with default setup)\n",
    "You can configure Git Proxy to match your setup, edit the cluster, and go to Advanced options -> Spark -> Environment variables. Supported environment variables are:\n",
    "- GIT_PROXY_ENABLE_SSL_VERIFICATION: You may want to disable SSL verification if you are using a self-signed certificate for your private Git server. Example: true/false\n",
    "- GIT_PROXY_CA_CERT_PATH: Or you can provide a CA cert file for SSL verification.\n",
    "\n",
    "**GIT_PROXY_CUSTOM_HTTP_PORT and GIT_PROXY_HTTP_PROXY are not available at this time**\n",
    "After updating the environment variables, please save and restart the cluster."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1649133805813433,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "enable_git_proxy_jupyter",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
